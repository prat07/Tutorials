{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn works only on numeric data stored as \"numpy arrays\" or \"scipy sparse matrices\".\n",
    "\n",
    "3 ways to load data into Scikit-Learn\n",
    "\n",
    "* Pandas DataFrame that consist of all numeric values of variables can be used too after converting categorical variables to numeric values.\n",
    "* loadtxt() function from numpy arrays - here too variables should contain numeric values\n",
    "* \"sklearn-pandas\" external library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display  #To display multiple outputs from a cell\n",
    "pd.set_option('display.max_rows', 40) #Limit max number of rows to display\n",
    "pd.set_option('expand_frame_repr', False) #To display all columns in a single horizontal view without line wraping\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Categorical variables - Ordinal\n",
    "There is information present in the order of values of the categorical variable. We must not loose that information while performing the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name         object\n",
       "Age         float64\n",
       "Gender       object\n",
       "Class        object\n",
       "Fare        float64\n",
       "Survival     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Class</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>211.34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>151.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>151.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>151.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>151.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>26.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>63.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>77.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>51.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>71.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>49.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>227.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>227.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>69.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>78.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>80.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>247.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>247.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>76.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>75.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>37.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>52.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>14.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>7.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>38.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>7.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>51.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>18.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>47.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>29.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>16.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>8.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>14.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>14.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>46.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>14.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>29.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1045 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Gender  Class    Fare  Survival\n",
       "0     29.0  Female      3  211.34         1\n",
       "1      1.0    Male      3  151.55         1\n",
       "2      2.0  Female      3  151.55         0\n",
       "3     30.0    Male      3  151.55         0\n",
       "4     25.0  Female      3  151.55         0\n",
       "5     48.0    Male      3   26.55         1\n",
       "6     63.0  Female      3   77.96         1\n",
       "7     39.0    Male      3    0.00         0\n",
       "8     53.0  Female      3   51.48         1\n",
       "9     71.0    Male      3   49.50         0\n",
       "10    47.0    Male      3  227.53         0\n",
       "11    18.0  Female      3  227.53         1\n",
       "12    24.0  Female      3   69.30         1\n",
       "13    26.0  Female      3   78.85         1\n",
       "14    80.0    Male      3   30.00         1\n",
       "15    24.0    Male      3  247.52         0\n",
       "16    50.0  Female      3  247.52         1\n",
       "17    32.0  Female      3   76.29         1\n",
       "18    36.0    Male      3   75.24         0\n",
       "19    37.0    Male      3   52.55         1\n",
       "...    ...     ...    ...     ...       ...\n",
       "1025  14.0  Female      1    7.85         0\n",
       "1026  22.0    Male      1    7.90         0\n",
       "1027  22.0    Male      1    9.00         0\n",
       "1028  33.0    Male      1    9.50         0\n",
       "1029  38.0  Female      1    7.23         1\n",
       "1030  51.0    Male      1    7.75         0\n",
       "1031  18.0    Male      1    6.50         0\n",
       "1032  21.0    Male      1    6.50         0\n",
       "1033  47.0  Female      1    7.00         1\n",
       "1034  29.0    Male      1   16.10         0\n",
       "1035  21.0    Male      1    7.25         0\n",
       "1036  27.0    Male      1    8.66         0\n",
       "1037  36.0    Male      1    9.50         0\n",
       "1038  27.0    Male      1   14.45         0\n",
       "1039  15.0  Female      1   14.45         1\n",
       "1040  46.0    Male      1    7.23         0\n",
       "1041  15.0  Female      1   14.45         0\n",
       "1042  27.0    Male      1    7.23         0\n",
       "1043  27.0    Male      1    7.23         0\n",
       "1044  29.0    Male      1    7.88         0\n",
       "\n",
       "[1045 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./TITANIC_DP_FS.csv\")\n",
    "display(df.dtypes)\n",
    "df = df.drop('Name', axis=1)\n",
    "\n",
    "class_mapping = {'1st': 3,\n",
    "                '2nd': 2,\n",
    "                '3rd': 1}\n",
    "\n",
    "survival_mapping = {'Survived': 1,\n",
    "                   'Died': 0}\n",
    "\n",
    "df['Class'] = df['Class'].map(class_mapping)\n",
    "df['Survival'] = df['Survival'].map(survival_mapping)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Categorical variables - Nominal\n",
    "There is no information present in the order of values of the categorical variable. We must not introduce any information while performing the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1045 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender_Female  Gender_Male\n",
       "0                 1            0\n",
       "1                 0            1\n",
       "2                 1            0\n",
       "3                 0            1\n",
       "4                 1            0\n",
       "5                 0            1\n",
       "6                 1            0\n",
       "7                 0            1\n",
       "8                 1            0\n",
       "9                 0            1\n",
       "10                0            1\n",
       "11                1            0\n",
       "12                1            0\n",
       "13                1            0\n",
       "14                0            1\n",
       "15                0            1\n",
       "16                1            0\n",
       "17                1            0\n",
       "18                0            1\n",
       "19                0            1\n",
       "...             ...          ...\n",
       "1025              1            0\n",
       "1026              0            1\n",
       "1027              0            1\n",
       "1028              0            1\n",
       "1029              1            0\n",
       "1030              0            1\n",
       "1031              0            1\n",
       "1032              0            1\n",
       "1033              1            0\n",
       "1034              0            1\n",
       "1035              0            1\n",
       "1036              0            1\n",
       "1037              0            1\n",
       "1038              0            1\n",
       "1039              1            0\n",
       "1040              0            1\n",
       "1041              1            0\n",
       "1042              0            1\n",
       "1043              0            1\n",
       "1044              0            1\n",
       "\n",
       "[1045 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.0</td>\n",
       "      <td>3</td>\n",
       "      <td>211.34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>151.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>151.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3</td>\n",
       "      <td>151.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>3</td>\n",
       "      <td>151.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48.0</td>\n",
       "      <td>3</td>\n",
       "      <td>26.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>63.0</td>\n",
       "      <td>3</td>\n",
       "      <td>77.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53.0</td>\n",
       "      <td>3</td>\n",
       "      <td>51.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>71.0</td>\n",
       "      <td>3</td>\n",
       "      <td>49.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47.0</td>\n",
       "      <td>3</td>\n",
       "      <td>227.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18.0</td>\n",
       "      <td>3</td>\n",
       "      <td>227.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>69.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26.0</td>\n",
       "      <td>3</td>\n",
       "      <td>78.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>80.0</td>\n",
       "      <td>3</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>247.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "      <td>247.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3</td>\n",
       "      <td>76.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36.0</td>\n",
       "      <td>3</td>\n",
       "      <td>75.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>37.0</td>\n",
       "      <td>3</td>\n",
       "      <td>52.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1045 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Class    Fare  Survival\n",
       "0     29.0      3  211.34         1\n",
       "1      1.0      3  151.55         1\n",
       "2      2.0      3  151.55         0\n",
       "3     30.0      3  151.55         0\n",
       "4     25.0      3  151.55         0\n",
       "5     48.0      3   26.55         1\n",
       "6     63.0      3   77.96         1\n",
       "7     39.0      3    0.00         0\n",
       "8     53.0      3   51.48         1\n",
       "9     71.0      3   49.50         0\n",
       "10    47.0      3  227.53         0\n",
       "11    18.0      3  227.53         1\n",
       "12    24.0      3   69.30         1\n",
       "13    26.0      3   78.85         1\n",
       "14    80.0      3   30.00         1\n",
       "15    24.0      3  247.52         0\n",
       "16    50.0      3  247.52         1\n",
       "17    32.0      3   76.29         1\n",
       "18    36.0      3   75.24         0\n",
       "19    37.0      3   52.55         1\n",
       "...    ...    ...     ...       ...\n",
       "1025  14.0      1    7.85         0\n",
       "1026  22.0      1    7.90         0\n",
       "1027  22.0      1    9.00         0\n",
       "1028  33.0      1    9.50         0\n",
       "1029  38.0      1    7.23         1\n",
       "1030  51.0      1    7.75         0\n",
       "1031  18.0      1    6.50         0\n",
       "1032  21.0      1    6.50         0\n",
       "1033  47.0      1    7.00         1\n",
       "1034  29.0      1   16.10         0\n",
       "1035  21.0      1    7.25         0\n",
       "1036  27.0      1    8.66         0\n",
       "1037  36.0      1    9.50         0\n",
       "1038  27.0      1   14.45         0\n",
       "1039  15.0      1   14.45         1\n",
       "1040  46.0      1    7.23         0\n",
       "1041  15.0      1   14.45         0\n",
       "1042  27.0      1    7.23         0\n",
       "1043  27.0      1    7.23         0\n",
       "1044  29.0      1    7.88         0\n",
       "\n",
       "[1045 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df = pd.read_csv(\"C:\\Users\\prati\\Desktop\\My_Creations\\Data_Preprocessing-Scikit\\TITANIC_NM.csv\")\n",
    "#df = df.drop('Name', axis=1)\n",
    "\n",
    "df_temp = pd.get_dummies(df[['Gender']])\n",
    "display(df_temp)\n",
    "\n",
    "df = df.drop('Gender', axis=1)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3</td>\n",
       "      <td>211.34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>151.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>151.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3</td>\n",
       "      <td>151.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3</td>\n",
       "      <td>151.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3</td>\n",
       "      <td>26.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3</td>\n",
       "      <td>77.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3</td>\n",
       "      <td>51.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>3</td>\n",
       "      <td>49.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3</td>\n",
       "      <td>227.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3</td>\n",
       "      <td>227.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>69.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3</td>\n",
       "      <td>78.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>247.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "      <td>247.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3</td>\n",
       "      <td>76.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3</td>\n",
       "      <td>75.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3</td>\n",
       "      <td>52.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1045 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender_Female  Gender_Male   Age  Class    Fare  Survival\n",
       "0                 1            0  29.0      3  211.34         1\n",
       "1                 0            1   1.0      3  151.55         1\n",
       "2                 1            0   2.0      3  151.55         0\n",
       "3                 0            1  30.0      3  151.55         0\n",
       "4                 1            0  25.0      3  151.55         0\n",
       "5                 0            1  48.0      3   26.55         1\n",
       "6                 1            0  63.0      3   77.96         1\n",
       "7                 0            1  39.0      3    0.00         0\n",
       "8                 1            0  53.0      3   51.48         1\n",
       "9                 0            1  71.0      3   49.50         0\n",
       "10                0            1  47.0      3  227.53         0\n",
       "11                1            0  18.0      3  227.53         1\n",
       "12                1            0  24.0      3   69.30         1\n",
       "13                1            0  26.0      3   78.85         1\n",
       "14                0            1  80.0      3   30.00         1\n",
       "15                0            1  24.0      3  247.52         0\n",
       "16                1            0  50.0      3  247.52         1\n",
       "17                1            0  32.0      3   76.29         1\n",
       "18                0            1  36.0      3   75.24         0\n",
       "19                0            1  37.0      3   52.55         1\n",
       "...             ...          ...   ...    ...     ...       ...\n",
       "1025              1            0  14.0      1    7.85         0\n",
       "1026              0            1  22.0      1    7.90         0\n",
       "1027              0            1  22.0      1    9.00         0\n",
       "1028              0            1  33.0      1    9.50         0\n",
       "1029              1            0  38.0      1    7.23         1\n",
       "1030              0            1  51.0      1    7.75         0\n",
       "1031              0            1  18.0      1    6.50         0\n",
       "1032              0            1  21.0      1    6.50         0\n",
       "1033              1            0  47.0      1    7.00         1\n",
       "1034              0            1  29.0      1   16.10         0\n",
       "1035              0            1  21.0      1    7.25         0\n",
       "1036              0            1  27.0      1    8.66         0\n",
       "1037              0            1  36.0      1    9.50         0\n",
       "1038              0            1  27.0      1   14.45         0\n",
       "1039              1            0  15.0      1   14.45         1\n",
       "1040              0            1  46.0      1    7.23         0\n",
       "1041              1            0  15.0      1   14.45         0\n",
       "1042              0            1  27.0      1    7.23         0\n",
       "1043              0            1  27.0      1    7.23         0\n",
       "1044              0            1  29.0      1    7.88         0\n",
       "\n",
       "[1045 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.concat([df_temp, df], axis = 1)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.  ,    0.  ,   29.  ,    3.  ,  211.34],\n",
       "       [   0.  ,    1.  ,    1.  ,    3.  ,  151.55],\n",
       "       [   1.  ,    0.  ,    2.  ,    3.  ,  151.55],\n",
       "       ..., \n",
       "       [   0.  ,    1.  ,   27.  ,    1.  ,    7.23],\n",
       "       [   0.  ,    1.  ,   27.  ,    1.  ,    7.23],\n",
       "       [   0.  ,    1.  ,   29.  ,    1.  ,    7.88]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       ..., \n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.iloc[:, 0:5].values)\n",
    "\n",
    "display(df.iloc[:, 5:6].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X, y = df.iloc[:, 0:5].values, df.iloc[:, 5:6].values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1045L, 5L)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1045L, 1L)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.  ,    0.  ,   29.  ,    3.  ,  211.34],\n",
       "       [   0.  ,    1.  ,    1.  ,    3.  ,  151.55],\n",
       "       [   1.  ,    0.  ,    2.  ,    3.  ,  151.55],\n",
       "       ..., \n",
       "       [   0.  ,    1.  ,   27.  ,    1.  ,    7.23],\n",
       "       [   0.  ,    1.  ,   27.  ,    1.  ,    7.23],\n",
       "       [   0.  ,    1.  ,   29.  ,    1.  ,    7.88]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X   # 2-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       ..., \n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y  # vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.  ,    0.  ,   29.  ,    3.  ,  211.34],\n",
       "       [   0.  ,    1.  ,    1.  ,    3.  ,  151.55],\n",
       "       [   1.  ,    0.  ,    2.  ,    3.  ,  151.55]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[[0, 1, 2]]   # rows 0,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.  ,    0.  ,   29.  ,    3.  ,  211.34],\n",
       "       [   0.  ,    1.  ,    1.  ,    3.  ,  151.55],\n",
       "       [   1.  ,    0.  ,    2.  ,    3.  ,  151.55],\n",
       "       [   0.  ,    1.  ,   30.  ,    3.  ,  151.55],\n",
       "       [   1.  ,    0.  ,   25.  ,    3.  ,  151.55]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]   # 5 first rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[500:510, 0]  # values from row 500 to row 510 at column 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:2]  # first two values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]  # first five values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prati\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.  ,   0.  ,  37.  ,   1.  ,   9.59],\n",
       "       [  1.  ,   0.  ,  16.  ,   3.  ,  86.5 ],\n",
       "       [  1.  ,   0.  ,   9.  ,   1.  ,  15.25],\n",
       "       ..., \n",
       "       [  0.  ,   1.  ,  22.  ,   1.  ,   7.78],\n",
       "       [  0.  ,   1.  ,  26.  ,   1.  ,   7.89],\n",
       "       [  1.  ,   0.  ,  30.  ,   1.  ,   6.95]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    \n",
    "\n",
    "display(X_train)\n",
    "display(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API design in Scikit-Learn\n",
    "\n",
    "All APIs in scikit-learn can be grouped in following classes\n",
    "* Estimator - Any API containing fit() method. Generally, contain fit() and predict() methods. Can have transform() method too.\n",
    "* Transformer - Any API containing transform() method. Generally, contain fit() and transform() methods. Hence, subset of estimator class.\n",
    "\n",
    "In general, all APIs in scikit-learn can be called as estimator as they all estimate using fit() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.,  0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([   1.  ,    1.  ,   76.  ,    3.  ,  512.33])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([   1.  ,    1.  ,   76.  ,    2.  ,  512.33])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalization\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "X_train_norm = mms.fit_transform(X_train)  # fit + transform\n",
    "X_test_norm = mms.transform(X_test)        # only transform\n",
    "\n",
    "# It should be kept in mind while performing distance based methods (also squared-error based ones) we must attempt to scale \n",
    "# the data, so that the feature with lesser significance might not end up dominating the objective function due to its larger range. \n",
    "# In addition, features having different unit should also be scaled thus providing each feature equal initial weightage and at \n",
    "# the end we will have a better prediction model.\n",
    "\n",
    "\n",
    "display(mms.data_min_ )    # Per feature minimum seen in the data (training data - as fit is applied only on training data)\n",
    "display(mms.data_max_)     # Per feature maximum seen in the data  (training data)\n",
    "display(mms.data_range_)   # Per feature range (data_max_ - data_min_) seen in the data (training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.37209302,   0.62790698,  30.16689466,   1.8125855 ,  37.76997264])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([  2.33639805e-01,   2.33639805e-01,   1.96100737e+02,\n",
       "         7.21373753e-01,   3.31483610e+03])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standardization\n",
    "\n",
    "# Standarization can be more practical than MinMax Scaler in many algorithms as they expect the data to have normal distribution\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)   # fit + transform\n",
    "X_test_std = stdsc.transform(X_test)         # only transform\n",
    "\n",
    "# Elements such as l1 ,l2 regularizer in linear models (logistic comes under this category) and RBF kernel in SVM in\n",
    "# objective function of learners assumes that all the features are centered around zero and have variance in the same order.\n",
    "\n",
    "display(stdsc.mean_)     # Per feature mean seen in the data (training data)\n",
    "display(stdsc.var_)      # Per feature variance seen in the data (training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.  ,   1.  ,  29.  ,   2.  ,  15.85])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([  1. ,   1. ,  18. ,   2. ,  28.7])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Robust Scaling - robust to outliers\n",
    "# This Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). \n",
    "# The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile).\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "rbtsc = RobustScaler()\n",
    "X_train_rbt = rbtsc.fit_transform(X_train)   # fit + transform\n",
    "X_test_rbt = rbtsc.transform(X_test)         # only transform\n",
    "\n",
    "display(rbtsc.center_)  # Per feature median seen in the data (training data)\n",
    "display(rbtsc.scale_)   # Per feature interquartile range seen in the data (training data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : Choosing between different methods of scaling features is a confusing choice, you have to dive deeper in your data and learner that you are going to use to reach the decision. For starters, you can try all the above methods and check cross validation score for making a choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Univariate methods\n",
    "* Univariate feature selection methods - each feature is evaluated independently with respect to the response variable. \n",
    "* Univariate feature selection is in general best to get a better understanding of the data, its structure and characteristics.\n",
    "* Not a recommended way since it does not take care of correlation between features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Models and Regularization\n",
    "* The idea is that the idea that when all features are on the same scale, Coefficients of regression models can be used for selecting and interpreting features the most important features should have the highest coefficients in the model,  \n",
    "while features uncorrelated with the output variables should have coefficient values close to zero\n",
    "\n",
    "* When there are multiple (linearly) correlated features (as is the case with very many real life datasets), the model becomes unstable, meaning that small changes in the data can cause large changes in the model (i.e. coefficient values), making model interpretation very difficult (so called multicollinearity problem)\n",
    "\n",
    "* This applies to linear regression as well as logistic regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Models\n",
    "* Regularization is a method for adding additional constraints or penalty to a model, with the goal of preventing overfitting and improving generalization. Instead of minimizing a loss function E(X,Y), the loss function to minimize becomes E(X,Y)+α∥w∥, where w is the vector of model coefficients, ∥⋅∥ is typically L1 or L2 norm and α is a tunable free parameter, specifying the amount of regularization (so α=0 implies an unregularized model)\n",
    "* For regression models, the two widely used regularization methods are L1 and L2 regularization, also called lasso and ridge regression when applied in linear regression as well as logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 regularization / Lasso\n",
    "* L1 regularization adds a penalty α∑|wi|  to the loss function (L1-norm). Since each non-zero coefficient adds to the penalty, it forces weak features to have zero as coefficients. Thus L1 regularization produces sparse solutions, inherently performing feature selection.\n",
    "* If we increase α further, the solution would be sparser and sparser, i.e. more and more features would have 0 as coefficients\n",
    "* L1 regularized regression is unstable in a similar way as unregularized linear models are, meaning that the coefficients (and thus feature ranks) can vary significantly even on small data changes when there are correlated features in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(731L, 5L)\n",
      "(731L, 1L)\n",
      "Lasso coef:  [  2.25089898e-01  -3.15904773e-16  -5.45199511e-02   1.44097071e-01\n",
      "   7.87665645e-03]\n",
      "Names:  Index([u'Gender_Female', u'Gender_Male', u'Age', u'Class', u'Fare'], dtype='object')\n",
      "Lasso Model:  [('Gender_Female', 0.22509), ('Gender_Male', -0.0), ('Age', -0.05452), ('Class', 0.144097), ('Fare', 0.007877)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=0.01)\n",
    "print X_train_std.shape\n",
    "print y_train.shape\n",
    "lasso.fit(X_train_std, y_train)\n",
    "print \"Lasso coef: \", lasso.coef_\n",
    "print \"Names: \", df.columns[df.columns != \"Survival\"]\n",
    "print \"Lasso Model: \", zip(df.columns[df.columns != \"Survival\"],map(lambda x: round(x, 6), lasso.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Logistic coef:  [[  8.31014405e-05  -1.08095979e+00  -2.93505380e-01   7.91465302e-01\n",
      "    4.09594372e-02]]\n",
      "Names:  Index([u'Gender_Female', u'Gender_Male', u'Age', u'Class', u'Fare'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lasso_logistic = LogisticRegression(penalty='l1', C=0.1) \n",
    "lasso_logistic.fit(X_train_std, y_train)\n",
    "print \"Lasso Logistic coef: \", lasso_logistic.coef_\n",
    "print \"Names: \", df.columns[df.columns != \"Survival\"]\n",
    "\n",
    "# penalty - can be 'l1' or 'l2'\n",
    "# C - Inverse of regularization strength (1/α), smaller values specify stronger regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### L2 regularization / Ridge regression\n",
    "* L2 regularization (called ridge regression for linear regression) adds the L2 norm penalty (α∑w<sup>2</sup>) to the loss function  \n",
    "* Since the coefficients are squared in the penalty expression, it has a different effect from L1-norm, namely it forces the coefficient values to be spread out more equally. For correlated features, it means that they tend to get similar coefficients\n",
    "* Example: Y=X1+X2, with strongly correlated X1 and X2, then for L1, the penalty is the same whether the learned model is Y=1∗X1+1∗X2 or Y=2∗X1+0∗X2. In both cases the penalty is 2∗α. For L2 however, the first model’s penalty is 1<sup>2</sup>+1<sup>2</sup>=2α, while for the second model is penalized with 2<sup>2</sup>+0<sup>2</sup>=4α\n",
    "* The effect of this is that models are much more stable (coefficients do not fluctuate on small data changes as is the case with unregularized or L1 models)\n",
    "* While L2 regularization does not perform feature selection the same way as L1 does, it is more useful for feature \"interpretation\": a predictive feature will get a non-zero coefficient, which is often not the case with L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge coef:  [[ 0.11503442 -0.11503442 -0.06838653  0.1535824   0.01403434]]\n",
      "Names:  Index([u'Gender_Female', u'Gender_Male', u'Age', u'Class', u'Fare'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=10)\n",
    "ridge.fit(X_train_std, y_train)\n",
    "print \"Ridge coef: \", ridge.coef_\n",
    "print \"Names: \", df.columns[df.columns != \"Survival\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "* Random forest has in-built feature selection characteristics\n",
    "* Note: If two or more features are highly correlated, one feature may be ranked very highly while the other correlated feature may be ranked lower. This is not an issue when we are concerned with prediction accuracy but it can lead to incorrect conclusion about feature importances when interpretation is concerned\n",
    "* One thing to point out though is that the difficulty of interpreting the importance/ranking of correlated variables is not random forest specific, but applies to most model based feature selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:  [ 0.13770352  0.14146328  0.3019057   0.09055831  0.32836919]\n",
      "Ranked List of feature importances:  [('Fare', 0.32836918531301218), ('Age', 0.30190570401439798), ('Gender_Male', 0.14146328414486936), ('Gender_Female', 0.13770351832408353), ('Class', 0.090558308203637153)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "feature_labels = df.columns[:-1]\n",
    "rf = RandomForestClassifier(n_estimators=1000)  # no. of trees to be used in random forest\n",
    "rf.fit(X_train_std, y_train)\n",
    "print \"Feature Importances: \", rf.feature_importances_\n",
    "print \"Ranked List of feature importances: \", sorted(zip(df.columns[:-1],rf.feature_importances_ ), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination\n",
    "* First, the estimator is trained on the initial set of features and weights are assigned to each one of them. Then, features whose absolute weights are the smallest are pruned from the current set features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached\n",
    "* The stability of RFE depends heavily on the type of model that is used for feature ranking at each iteration. Just as non-regularized regression can be unstable, so can RFE when utilizing it, while using ridge regression can provide more stable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 4, 2, 5])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index([u'Gender_Female', u'Gender_Male', u'Age', u'Class', u'Fare'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked List of feature importances:  [('Gender_Male', 1), ('Class', 2), ('Gender_Female', 3), ('Age', 4), ('Fare', 5)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "rfe = RFE(LinearRegression(), n_features_to_select=1) # rank all features, i.e continue the elimination until the last one\n",
    "rfe.fit(X_train_std, y_train)\n",
    "display(rfe.ranking_)\n",
    "display(df.columns[:-1])\n",
    "print \"Ranked List of feature importances: \", sorted(zip(df.columns[:-1],rfe.ranking_ ), key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability Selection\n",
    "* The high level idea is to apply a feature selection algorithm on different subsets of data and with different subsets of features. After repeating the process a number of times, the selection results can be aggregated, for example by checking how many times a feature ended up being selected as important when it was in an inspected feature subset.\n",
    "* We can expect strong features to have scores close to 100%, since they are always selected when possible. Weaker, but still relevant features will also have non-zero scores.\n",
    "* Sklearn implements stability selection in the \"randomized lasso\" and \"randomized logistics regression\" classes.\n",
    "* Stability selection is useful for both pure feature selection to reduce overfitting, but also for data interpretation: in general, good features won’t get 0 as coefficients just because there are similar, correlated features in the dataset (as is the case with lasso). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked List of feature importances:  [('Gender_Female', 0.55500000000000005), ('Class', 0.47999999999999998), ('Gender_Male', 0.255), ('Fare', 0.044999999999999998), ('Age', 0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prati\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:57: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RandomizedLasso\n",
    "rlasso = RandomizedLasso(alpha=0.005)\n",
    "rlasso.fit(X_train_std, y_train)\n",
    "print \"Ranked List of feature importances: \", sorted(zip(df.columns[:-1],rlasso.scores_ ), key=lambda x:x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* When selecting top features for model performance improvement, it is easy to verify if a particular method works well against alternatives simply by doing cross-validation.\n",
    "* It’s not as straightforward when using feature ranking for data interpretation, where stability of the ranking method is crucial and a method that doesn’t have this property (such as lasso) could easily lead to incorrect conclusions.\n",
    "* What can help there is subsampling the data and running the selection algorithms on the subsets. If the results are consistent across the subsets, it is relatively safe to trust the stability of the method on this particular data and therefor straightforward to interpret the data in terms of the ranking."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
